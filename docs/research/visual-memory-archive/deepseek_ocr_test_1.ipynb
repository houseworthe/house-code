{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: DeepSeek-OCR Accuracy Test\n",
    "\n",
    "**Objective**: Test OCR accuracy on code-heavy conversation images.\n",
    "\n",
    "**Target**: ‚â•90% character accuracy to proceed to Phase 3.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
    "2. **Run cells in order**: Don't skip cells\n",
    "3. **Upload test image**: When prompted in Cell 3\n",
    "4. **Document results**: Copy final output to `tests/PHASE2_RESULTS.md`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Install Dependencies (~5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers==4.46.3 tokenizers==0.20.3 einops pillow easydict addict\n",
    "!pip install -q flash-attn --no-build-isolation\n",
    "\n",
    "# Verify GPU availability\n",
    "import torch\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"üéÆ GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üéÆ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No GPU detected. This will be VERY slow.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Download DeepSeek-OCR Model (~10 min, ~10GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "print(\"Downloading DeepSeek-OCR model (~10GB)...\")\n",
    "print(\"This will take ~10 minutes on Colab's fast network.\\n\")\n",
    "\n",
    "model_path = snapshot_download(\n",
    "    repo_id='deepseek-ai/DeepSeek-OCR',\n",
    "    local_dir='/content/deepseek-ocr',\n",
    "    local_dir_use_symlinks=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Model downloaded to: {model_path}\")\n",
    "print(f\"‚úì Size: {sum(os.path.getsize(os.path.join(dirpath, filename)) for dirpath, dirnames, filenames in os.walk(model_path) for filename in filenames) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Upload Test Image (~5 sec)\n",
    "\n",
    "**Action Required**: Upload `/tmp/poc_long_conversation.png` when prompted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"üì§ Please upload: /tmp/poc_long_conversation.png\\n\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move to predictable path\n",
    "image_filename = list(uploaded.keys())[0]\n",
    "shutil.move(image_filename, '/content/test_image.png')\n",
    "\n",
    "# Verify\n",
    "from PIL import Image\n",
    "img = Image.open('/content/test_image.png')\n",
    "print(f\"\\n‚úì Image ready at: /content/test_image.png\")\n",
    "print(f\"‚úì Dimensions: {img.width}x{img.height}\")\n",
    "print(f\"‚úì Format: {img.format}\")\n",
    "print(f\"‚úì Mode: {img.mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Define Original Text (instant)\n",
    "\n",
    "This is the ground truth from `tests/poc_long_conversation.py:create_long_conversation()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original text from tests/poc_long_conversation.py (lines 22-168)\n",
    "ORIGINAL_TEXT = \"\"\"[USER]: I'm trying to implement a recursive function to find all files in a directory, but it's not working as expected. Here's my code:\n",
    "\n",
    "import os\n",
    "\n",
    "def find_files(path, pattern):\n",
    "    results = []\n",
    "    for item in os.listdir(path):\n",
    "        if item.endswith(pattern):\n",
    "            results.append(item)\n",
    "    return results\n",
    "\n",
    "files = find_files('/Users/me/Documents', '.txt')\n",
    "print(files)\n",
    "\n",
    "[ASSISTANT]: Your function is only checking the immediate directory, not recursing into subdirectories. Here's a fixed version:\n",
    "\n",
    "import os\n",
    "\n",
    "def find_files(path, pattern):\n",
    "    results = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(pattern):\n",
    "                full_path = os.path.join(root, file)\n",
    "                results.append(full_path)\n",
    "    return results\n",
    "\n",
    "files = find_files('/Users/me/Documents', '.txt')\n",
    "print(f'Found {len(files)} files:')\n",
    "for f in files:\n",
    "    print(f'  {f}')\n",
    "\n",
    "The key changes:\n",
    "1. Use os.walk() instead of os.listdir() - this recursively traverses directories\n",
    "2. Store full paths using os.path.join()\n",
    "3. Added better output formatting\n",
    "\n",
    "[USER]: That works! But now I want to add a filter to exclude certain directories like __pycache__ and .git. How do I do that?\n",
    "\n",
    "[ASSISTANT]: You can modify the dirs list in-place during os.walk() to skip directories:\n",
    "\n",
    "import os\n",
    "\n",
    "def find_files(path, pattern, exclude_dirs=None):\n",
    "    if exclude_dirs is None:\n",
    "        exclude_dirs = ['__pycache__', '.git', 'node_modules', '.venv']\n",
    "\n",
    "    results = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # Remove excluded directories from dirs in-place\n",
    "        dirs[:] = [d for d in dirs if d not in exclude_dirs]\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith(pattern):\n",
    "                full_path = os.path.join(root, file)\n",
    "                results.append(full_path)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "files = find_files('/Users/me/Documents', '.txt')\n",
    "print(f'Found {len(files)} .txt files')\n",
    "\n",
    "# Or with custom exclusions\n",
    "files = find_files(\n",
    "    '/Users/me/Projects',\n",
    "    '.py',\n",
    "    exclude_dirs=['build', 'dist', 'venv']\n",
    ")\n",
    "\n",
    "The key trick is `dirs[:] = [...]` which modifies the list in-place. This tells os.walk() to skip those directories.\n",
    "\n",
    "[USER]: Perfect! One more thing - can I make it case-insensitive? I want to match both .txt and .TXT files.\n",
    "\n",
    "[ASSISTANT]: Sure! Use str.lower() for case-insensitive matching:\n",
    "\n",
    "import os\n",
    "\n",
    "def find_files(path, pattern, exclude_dirs=None, case_sensitive=True):\n",
    "    if exclude_dirs is None:\n",
    "        exclude_dirs = ['__pycache__', '.git', 'node_modules', '.venv']\n",
    "\n",
    "    # Normalize pattern for case-insensitive matching\n",
    "    if not case_sensitive:\n",
    "        pattern = pattern.lower()\n",
    "\n",
    "    results = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        dirs[:] = [d for d in dirs if d not in exclude_dirs]\n",
    "\n",
    "        for file in files:\n",
    "            # Compare lowercased filename if case-insensitive\n",
    "            filename = file.lower() if not case_sensitive else file\n",
    "\n",
    "            if filename.endswith(pattern):\n",
    "                full_path = os.path.join(root, file)\n",
    "                results.append(full_path)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Case-insensitive search\n",
    "files = find_files('/Users/me/Documents', '.txt', case_sensitive=False)\n",
    "# Will match: document.txt, README.TXT, notes.Txt, etc.\n",
    "\n",
    "[USER]: Excellent! This is exactly what I needed. Thanks!\n",
    "\n",
    "[ASSISTANT]: You're welcome! A few best practices to consider:\n",
    "\n",
    "1. **Error handling**: Add try-except for permission errors:\n",
    "   ```python\n",
    "   try:\n",
    "       for root, dirs, files in os.walk(path):\n",
    "           # ... your code ...\n",
    "   except PermissionError as e:\n",
    "       print(f\"Permission denied: {e}\")\n",
    "   ```\n",
    "\n",
    "2. **Performance**: For large directories, consider using pathlib:\n",
    "   ```python\n",
    "   from pathlib import Path\n",
    "\n",
    "   def find_files_pathlib(path, pattern, case_sensitive=True):\n",
    "       p = Path(path)\n",
    "       if case_sensitive:\n",
    "           return list(p.rglob(f'*{pattern}'))\n",
    "       else:\n",
    "           # pathlib doesn't support case-insensitive, use os.walk\n",
    "           pass\n",
    "   ```\n",
    "\n",
    "3. **Testing**: Add unit tests:\n",
    "   ```python\n",
    "   def test_find_files():\n",
    "       # Create temp directory structure\n",
    "       import tempfile\n",
    "       with tempfile.TemporaryDirectory() as tmpdir:\n",
    "           # Create test files\n",
    "           Path(tmpdir, 'test.txt').touch()\n",
    "           Path(tmpdir, 'subdir').mkdir()\n",
    "           Path(tmpdir, 'subdir', 'nested.txt').touch()\n",
    "\n",
    "           # Test\n",
    "           results = find_files(tmpdir, '.txt')\n",
    "           assert len(results) == 2\n",
    "   ```\n",
    "\n",
    "Let me know if you need help with any of these!\"\"\"\n",
    "\n",
    "print(f\"Original text: {len(ORIGINAL_TEXT)} characters\")\n",
    "print(f\"Estimated tokens: ~{len(ORIGINAL_TEXT) // 4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Load Model & Run OCR (~10-30 sec inference)\n",
    "\n",
    "This is the critical test. Expected latency on T4: 10-30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import time\n",
    "\n",
    "print(\"Loading DeepSeek-OCR model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    '/content/deepseek-ocr',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    '/content/deepseek-ocr',\n",
    "    _attn_implementation='flash_attention_2',\n",
    "    trust_remote_code=True\n",
    ").eval().cuda().to(torch.bfloat16)\n",
    "\n",
    "print(\"‚úì Model loaded to GPU\\n\")\n",
    "\n",
    "# Run OCR\n",
    "print(\"Running OCR inference...\")\n",
    "print(\"(This may take 10-30 seconds on T4 GPU)\\n\")\n",
    "\n",
    "start = time.time()\n",
    "result = model.infer(\n",
    "    tokenizer,\n",
    "    prompt=\"<image>\\nFree OCR.\",\n",
    "    image_file='/content/test_image.png',\n",
    "    base_size=1024,\n",
    "    image_size=1024,\n",
    "    crop_mode=False,\n",
    "    save_results=False\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"‚úì OCR complete in {elapsed:.2f}s\")\n",
    "print(f\"‚úì Output: {len(result)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Calculate Accuracy & Display Results\n",
    "\n",
    "Character-level accuracy using difflib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "# Calculate accuracy\n",
    "matcher = difflib.SequenceMatcher(None, ORIGINAL_TEXT.strip(), result.strip())\n",
    "accuracy = matcher.ratio() * 100\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ PHASE 2 RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"CHARACTER ACCURACY: {accuracy:.2f}%\")\n",
    "print(f\"LATENCY: {elapsed:.2f}s\")\n",
    "print(f\"ORIGINAL: {len(ORIGINAL_TEXT)} chars\")\n",
    "print(f\"OCR OUTPUT: {len(result)} chars\")\n",
    "print(f\"DIFFERENCE: {abs(len(result) - len(ORIGINAL_TEXT))} chars\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Token compression estimate\n",
    "text_tokens = len(ORIGINAL_TEXT) // 4\n",
    "visual_tokens = 256 * 2  # 2 pages at 1024x1024 = 256 tokens each\n",
    "token_compression = text_tokens / visual_tokens\n",
    "print(f\"\\nEst. text tokens: ~{text_tokens}\")\n",
    "print(f\"Visual tokens (2 pages): {visual_tokens}\")\n",
    "print(f\"Token compression: {token_compression:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Show Comparisons\n",
    "\n",
    "Visual comparison of original vs OCR output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 800 chars comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÑ ORIGINAL (first 800 chars):\")\n",
    "print(\"=\"*70)\n",
    "print(ORIGINAL_TEXT[:800])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÑ OCR OUTPUT (first 800 chars):\")\n",
    "print(\"=\"*70)\n",
    "print(result[:800])\n",
    "\n",
    "# Show differences if accuracy < 100%\n",
    "if accuracy < 100:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚ö†Ô∏è  SAMPLE DIFFERENCES (first 20):\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    diff_count = 0\n",
    "    for i, s in enumerate(difflib.ndiff(ORIGINAL_TEXT[:500], result[:500])):\n",
    "        if s[0] != ' ':\n",
    "            print(f\"Pos {i}: {repr(s)}\")\n",
    "            diff_count += 1\n",
    "            if diff_count >= 20:\n",
    "                print(f\"... (showing first 20 of many differences)\")\n",
    "                break\n",
    "else:\n",
    "    print(\"\\n‚úÖ PERFECT MATCH: 100% accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Decision Tree\n",
    "\n",
    "Based on accuracy, determine next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ DECISION FOR PHASE 3\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if accuracy >= 90:\n",
    "    print(\"\\n‚úÖ SUCCESS: Accuracy ‚â•90%\")\n",
    "    print(\"\\nNext Steps:\")\n",
    "    print(\"1. Document results in tests/PHASE2_RESULTS.md\")\n",
    "    print(\"2. Proceed to Phase 3: Full Implementation\")\n",
    "    print(\"   - Rewrite MCP server with OCR functions\")\n",
    "    print(\"   - Update client (rosie_client.py) for archive/reconstruct\")\n",
    "    print(\"   - Integrate with garbage collector\")\n",
    "    print(\"   - Write comprehensive tests\")\n",
    "    print(\"\\nüí° Visual memory compression is VIABLE for production.\")\n",
    "    \n",
    "elif accuracy >= 85:\n",
    "    print(\"\\n‚ö†Ô∏è  MARGINAL: Accuracy 85-89%\")\n",
    "    print(\"\\nNext Steps:\")\n",
    "    print(\"1. Iterate on rendering:\")\n",
    "    print(\"   - Try different fonts (DejaVu Sans Mono, Courier)\")\n",
    "    print(\"   - Adjust font size (12pt, 14pt, 16pt)\")\n",
    "    print(\"   - Test grayscale vs color\")\n",
    "    print(\"   - Disable syntax highlighting\")\n",
    "    print(\"2. Try different OCR prompts:\")\n",
    "    print(\"   - '<image>\\\\n<|grounding|>OCR this image.'\")\n",
    "    print(\"   - '<image>\\\\n<|grounding|>Convert to markdown.'\")\n",
    "    print(\"3. Re-test with adjustments\")\n",
    "    print(\"\\nüí° Close, but needs optimization before production.\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå INSUFFICIENT: Accuracy <85%\")\n",
    "    print(\"\\nNext Steps:\")\n",
    "    print(\"1. Document findings in tests/PHASE2_FINDINGS.md\")\n",
    "    print(\"2. Pivot to alternative approaches:\")\n",
    "    print(\"   Option A: Hybrid (PNG + text embeddings)\")\n",
    "    print(\"   Option B: Pure summarization (no visual compression)\")\n",
    "    print(\"   Option C: Skip visual memory entirely\")\n",
    "    print(\"3. Update project roadmap\")\n",
    "    print(\"\\nüí° Visual memory compression NOT viable with current approach.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"üìä Summary: {accuracy:.2f}% accuracy in {elapsed:.2f}s\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
